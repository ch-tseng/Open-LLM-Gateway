import streamlit as st
import os
import re
import json
import random
import string
import datetime
import pandas as pd
from pathlib import Path
import shutil
import configparser

# è¨­å®šé é¢é…ç½®å’Œæ¨™é¡Œ
st.set_page_config(
    page_title="APIé‡‘é‘°ç®¡ç†é é¢",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å¸¸æ•¸å®šç¾©
HISTORY_APIKEY_DIR = "../history_apikey"
API_KEYS_FILE = "api_keys.json"  # å­˜å„²æ‰€æœ‰APIé‡‘é‘°ä¿¡æ¯çš„æ–‡ä»¶
DISABLED_MARK = "_disabled"  # ç”¨æ–¼æ¨™è¨˜å·²åœç”¨çš„APIé‡‘é‘°

# è¨­å®šç™»å…¥å¯†ç¢¼ï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰ä½¿ç”¨æ›´å®‰å…¨çš„èªè­‰æ–¹å¼ï¼‰
ADMIN_PASSWORD = "admin123"

# ç¢ºä¿APIé‡‘é‘°ç›®éŒ„å­˜åœ¨
os.makedirs(HISTORY_APIKEY_DIR, exist_ok=True)

# åŠ è¼‰APIé‡‘é‘°æ•¸æ“š
def load_api_keys():
    api_keys_path = os.path.join(HISTORY_APIKEY_DIR, API_KEYS_FILE)
    if os.path.exists(api_keys_path):
        with open(api_keys_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

# ä¿å­˜APIé‡‘é‘°æ•¸æ“š
def save_api_keys(api_keys):
    api_keys_path = os.path.join(HISTORY_APIKEY_DIR, API_KEYS_FILE)
    with open(api_keys_path, 'w', encoding='utf-8') as f:
        json.dump(api_keys, f, ensure_ascii=False, indent=4)

# ç”¢ç”Ÿæ–°çš„APIé‡‘é‘°
def generate_apikey(prefix):
    """ç”¢ç”Ÿæ ¼å¼ç‚º {å‰ç¶´}-{ç•¶å‰æ—¥æœŸ}-{6ä½éš¨æ©Ÿå­—ç¬¦} çš„APIé‡‘é‘°"""
    date_part = datetime.datetime.now().strftime("%Y%m%d")
    random_part = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))
    return f"{prefix}-{date_part}-{random_part}"

# é©—è­‰APIé‡‘é‘°æ ¼å¼
def validate_apikey_format(apikey):
    """é©—è­‰APIé‡‘é‘°æ ¼å¼"""
    pattern = r"^[A-Z0-9]{2,8}-\d{8}-[a-z0-9]{6}$"
    return bool(re.match(pattern, apikey))

# ç²å–APIé‡‘é‘°ä½¿ç”¨çµ±è¨ˆ
def get_apikey_stats():
    """å¾history_apikeyç›®éŒ„ç²å–æ‰€æœ‰APIé‡‘é‘°çš„ä½¿ç”¨çµ±è¨ˆ"""
    api_keys_data = load_api_keys() # Changed variable name for clarity
    stats = []
    
    # éæ­·history_apikeyç›®éŒ„ä¸­çš„æ‰€æœ‰APIé‡‘é‘°ç›®éŒ„
    if not os.path.exists(HISTORY_APIKEY_DIR):
        print(f"Warning: API key history directory not found: {HISTORY_APIKEY_DIR}")
        return stats
        
    for apikey_dir_name in os.listdir(HISTORY_APIKEY_DIR):
        apikey_path = os.path.join(HISTORY_APIKEY_DIR, apikey_dir_name)
        
        # è·³ééç›®éŒ„é …æˆ–APIé‡‘é‘°æ•¸æ“šæ–‡ä»¶
        if not os.path.isdir(apikey_path) or apikey_dir_name == API_KEYS_FILE:
            continue
        
        # ç²å–APIé‡‘é‘°åç¨± (åŸå§‹ç›®éŒ„åï¼Œå¯èƒ½åŒ…å« _disabled)
        raw_apikey_name = apikey_dir_name
        
        is_disabled = raw_apikey_name.endswith(DISABLED_MARK)
        if is_disabled:
            actual_apikey = raw_apikey_name[:-len(DISABLED_MARK)]
        else:
            actual_apikey = raw_apikey_name

        # æª¢æŸ¥æ˜¯å¦ç‚ºæœ‰æ•ˆçš„APIé‡‘é‘°æ ¼å¼ (é‡å° actual_apikey)
        if not validate_apikey_format(actual_apikey):
            print(f"Skipping directory with invalid API key format: {actual_apikey}")
            continue
            
        total_requests = 0
        tokens_in = 0
        tokens_out = 0
        last_access_dt = None # Use datetime object for comparison
        
        # éæ­·APIé‡‘é‘°ç›®éŒ„ä¸­çš„æ‰€æœ‰æ—¥èªŒæ–‡ä»¶ (e.g., YYYYMMDD.txt)
        for log_file_name in os.listdir(apikey_path):
            if not log_file_name.endswith('.txt'): # Assuming logs are .txt files
                continue
                
            log_file_path = os.path.join(apikey_path, log_file_name)
            
            try:
                with open(log_file_path, 'r', encoding='utf-8') as f:
                    for line_number, line in enumerate(f):
                        line = line.strip()
                        if not line:
                            continue

                        total_requests += 1 # Count each non-empty line as a request attempt

                        # Regex to capture relevant parts from the new log format
                        # Example: [2024-05-15 10:00:00] Type: chat, Model: openai/gpt-3.5, APIKeySuffix: ...key, PromptTokens: 10, CompletionTokens: 20, TotalTokens: 30, StatusCode: 200
                        match = re.search(
                            r"""^\[(.*?)\]                        # Timestamp (e.g., 2024-05-15 10:00:00)
                            .*?Type:\s*(embedding|chat|chat_stream_attempt|chat_stream_completed|chat_error)  # Type
                            .*?Model:\s*(.*?)                      # Model Name
                            .*?APIKeySuffix:\s*(.*?)               # API Key Suffix
                            .*?PromptTokens:\s*(\d+)               # Prompt Tokens
                            .*?CompletionTokens:\s*(\d+)           # Completion Tokens
                            .*?TotalTokens:\s*(\d+)                 # Total Tokens
                            .*?StatusCode:\s*(\d+)                 # Status Code
                            (?:.*?Input:\s*(.*?))?                  # Optional Input Summary
                            (?:.*?Output:\s*(.*?))?                 # Optional Output Summary
                            (?:.*?Error:\s*(.*?))?$                 # Optional Error Message
                            """, 
                            line, 
                            re.VERBOSE
                        )

                        if match:
                            timestamp_str = match.group(1)
                            # request_type = match.group(2) # Not used for current stats, but available
                            # model_name_logged = match.group(3) # Not used for current stats
                            prompt_tokens_val = int(match.group(5))
                            completion_tokens_val = int(match.group(6))
                            # total_tokens_val = int(match.group(7)) # Can be used or re-calculated
                            status_code_val = int(match.group(8))

                            # Only add to token counts if request was successful (e.g., StatusCode 200)
                            # You might want to adjust this logic based on how errors are logged or if you want to count tokens for failed requests too.
                            if 200 <= status_code_val < 300: # Consider 2xx as success for token counting
                                tokens_in += prompt_tokens_val
                                tokens_out += completion_tokens_val
                            
                            try:
                                current_access_dt = datetime.datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")
                                if last_access_dt is None or current_access_dt > last_access_dt:
                                    last_access_dt = current_access_dt
                            except ValueError:
                                print(f"Warning: Could not parse timestamp '{timestamp_str}' in {log_file_path}, line {line_number + 1}")
                        else:
                            # Fallback for old log format or lines that don't match
                            # This part tries to salvage data if old logs exist or for simpler log lines.
                            # It might be less accurate or conflict if new logs are partially formed.
                            # Consider removing or adjusting this fallback if only new log format is expected.
                            legacy_token_match = re.search(r'Tokens: (\d+)', line)
                            if legacy_token_match:
                                tokens_val = int(legacy_token_match.group(1))
                                tokens_in += tokens_val # Old format didn't distinguish in/out well
                                # tokens_out += int(tokens_val * 0.7) # Old approximation
                            
                            legacy_ts_match = re.search(r'\[(.*?)]', line)
                            if legacy_ts_match:
                                try:
                                    current_access_dt = datetime.datetime.strptime(legacy_ts_match.group(1), "%Y-%m-%d %H:%M:%S")
                                    if last_access_dt is None or current_access_dt > last_access_dt:
                                        last_access_dt = current_access_dt
                                except ValueError:
                                    pass # Ignore if timestamp in old format is also unparseable
                            # print(f"Warning: Could not parse log line in {log_file_path}, line {line_number + 1}: {line[:100]}...")
            except Exception as e:
                print(f"Error reading or processing log file {log_file_path}: {e}")
                continue # Skip to next log file if one is broken
        
        # ç²å–å‰µå»ºæ™‚é–“ (å¾APIé‡‘é‘°çš„æ—¥æœŸéƒ¨åˆ†ï¼Œæˆ–å¾ api_keys_data)
        key_creation_info = api_keys_data.get(actual_apikey, {}).get("created_at")
        if key_creation_info:
            # Assuming created_at is stored as "YYYY-MM-DD HH:MM:SS"
            created_at_str = key_creation_info.split(' ')[0] # Get just the date part
        else:
            try:
                # Fallback to parsing from key name if not in api_keys.json (e.g. manually created folders)
                date_part_from_key = actual_apikey.split('-')[1]
                created_at_str = f"{date_part_from_key[:4]}-{date_part_from_key[4:6]}-{date_part_from_key[6:8]}"
            except IndexError:
                created_at_str = "æœªçŸ¥"
        
        # ç²å–æè¿°ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        description = api_keys_data.get(actual_apikey, {}).get("description", "")
        
        # æ·»åŠ åˆ°çµ±è¨ˆåˆ—è¡¨
        stats.append({
            "api_key": actual_apikey,
            "created_at": created_at_str,
            "last_access": last_access_dt.strftime("%Y-%m-%d %H:%M:%S") if last_access_dt else "å¾æœªä½¿ç”¨",
            "total_requests": total_requests,
            "tokens_in": tokens_in,
            "tokens_out": tokens_out,
            "description": description,
            "is_disabled": is_disabled
        })
    
    return stats

# åˆªé™¤APIé‡‘é‘°
def delete_apikey(apikey):
    """åˆªé™¤æŒ‡å®šçš„APIé‡‘é‘°åŠå…¶æ‰€æœ‰æ—¥èªŒ"""
    # åˆªé™¤APIé‡‘é‘°ç›®éŒ„
    apikey_path = os.path.join(HISTORY_APIKEY_DIR, apikey)
    if os.path.exists(apikey_path):
        shutil.rmtree(apikey_path)
    
    # å¾APIé‡‘é‘°é…ç½®ä¸­åˆªé™¤
    api_keys = load_api_keys()
    if apikey in api_keys:
        del api_keys[apikey]
        save_api_keys(api_keys)
    
    return True

# åœç”¨/å•Ÿç”¨APIé‡‘é‘°
def toggle_apikey_status(apikey, is_disabled):
    """åœç”¨æˆ–å•Ÿç”¨APIé‡‘é‘°"""
    api_keys = load_api_keys()
    
    # åŸç›®éŒ„è·¯å¾„
    orig_path = os.path.join(HISTORY_APIKEY_DIR, apikey)
    
    if is_disabled:
        # åœç”¨APIé‡‘é‘°
        new_key = f"{apikey}{DISABLED_MARK}"
        new_path = os.path.join(HISTORY_APIKEY_DIR, new_key)
    else:
        # å•Ÿç”¨APIé‡‘é‘°
        new_key = apikey.replace(DISABLED_MARK, "")
        new_path = os.path.join(HISTORY_APIKEY_DIR, new_key)
    
    # é‡å‘½åç›®éŒ„
    if os.path.exists(orig_path):
        os.rename(orig_path, new_path)
    
    # æ›´æ–°é…ç½®
    if apikey in api_keys:
        api_keys[new_key] = api_keys[apikey]
        del api_keys[apikey]
    
    save_api_keys(api_keys)
    return True

# æ·»åŠ APIé‡‘é‘°åˆ°ç™½åå–®
def add_to_whitelist(apikey, description=""):
    """å°‡APIé‡‘é‘°æ·»åŠ åˆ°ç™½åå–®"""
    api_keys = load_api_keys()
    api_keys[apikey] = {
        "created_at": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "description": description
    }
    save_api_keys(api_keys)
    
    # å‰µå»ºAPIé‡‘é‘°ç›®éŒ„
    apikey_path = os.path.join(HISTORY_APIKEY_DIR, apikey)
    os.makedirs(apikey_path, exist_ok=True)
    
    return True

# æ›´æ–°APIé‡‘é‘°æè¿°
def update_apikey_description(apikey, description):
    """æ›´æ–°APIé‡‘é‘°æè¿°"""
    api_keys = load_api_keys()
    if apikey in api_keys:
        api_keys[apikey]["description"] = description
        save_api_keys(api_keys)
        return True
    return False

# æ›´æ–°.envæ–‡ä»¶ä¸­çš„ç™½åå–®
def update_env_whitelist():
    """æ›´æ–°ä¸».envæ–‡ä»¶ä¸­çš„APIé‡‘é‘°ç™½åå–®"""
    api_keys = load_api_keys()
    active_keys = [key for key in api_keys.keys() if not key.endswith(DISABLED_MARK)]
    
    env_path = os.path.join("..", ".env")
    if os.path.exists(env_path):
        # è®€å–ç¾æœ‰.envå…§å®¹
        with open(env_path, 'r', encoding='utf-8') as f:
            env_content = f.read()
        
        # æ›´æ–°api_keys_whitelisté …
        whitelist_line = f"api_keys_whitelist={','.join(active_keys)}"
        
        # æª¢æŸ¥æ˜¯å¦å·²æœ‰api_keys_whitelistè¡Œ
        if "api_keys_whitelist=" in env_content:
            # æ›¿æ›ç¾æœ‰è¡Œ
            env_content = re.sub(r"api_keys_whitelist=.*", whitelist_line, env_content)
        else:
            # æ·»åŠ æ–°è¡Œ
            env_content += f"\n{whitelist_line}"
        
        # å¯«å›æ–‡ä»¶
        with open(env_path, 'w', encoding='utf-8') as f:
            f.write(env_content)
        
        return True
    return False

# ä¸»æ‡‰ç”¨ç¨‹åº
def main():
    st.title("ğŸ”‘ APIé‡‘é‘°ç®¡ç†é é¢")
    
    # ç°¡å–®çš„ç™»éŒ„ç³»çµ±
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    
    if not st.session_state.authenticated:
        with st.form("login_form"):
            password = st.text_input("è«‹è¼¸å…¥ç®¡ç†å“¡å¯†ç¢¼", type="password")
            submit = st.form_submit_button("ç™»å…¥")
            
            if submit:
                if password == ADMIN_PASSWORD:
                    st.session_state.authenticated = True
                    st.rerun()
                else:
                    st.error("å¯†ç¢¼éŒ¯èª¤")
        return
    
    # ä¸»ç•Œé¢ï¼ˆç™»å…¥å¾Œï¼‰
    tab1, tab2 = st.tabs(["APIé‡‘é‘°ç®¡ç†", "ç”¢ç”Ÿæ–°APIé‡‘é‘°"])
    
    # æ¨™ç±¤1ï¼šAPIé‡‘é‘°ç®¡ç†
    with tab1:
        st.header("APIé‡‘é‘°åˆ—è¡¨åŠä½¿ç”¨çµ±è¨ˆ")
        
        # ç²å–APIé‡‘é‘°çµ±è¨ˆæ•¸æ“š
        apikey_stats = get_apikey_stats()
        
        if not apikey_stats:
            st.info("å°šæœªæ‰¾åˆ°ä»»ä½•APIé‡‘é‘°è¨˜éŒ„ã€‚è«‹å…ˆç”¢ç”Ÿæ–°çš„APIé‡‘é‘°ã€‚")
        else:
            # è½‰æ›ç‚ºDataFrameä»¥ä¾¿é¡¯ç¤º
            df = pd.DataFrame(apikey_stats)
            
            # æ·»åŠ æ“ä½œæŒ‰éˆ•çš„å ä½åˆ—
            df['æ“ä½œ'] = None
            
            # é¡¯ç¤ºè¡¨æ ¼
            st.dataframe(df[['api_key', 'description', 'created_at', 'last_access', 'total_requests', 'tokens_in', 'tokens_out', 'is_disabled']], hide_index=True)
            
            # åˆªé™¤å’Œåœç”¨æŒ‰éˆ•
            st.subheader("APIé‡‘é‘°æ“ä½œ")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                selected_key = st.selectbox("é¸æ“‡APIé‡‘é‘°", [item["api_key"] for item in apikey_stats])
            
            with col2:
                is_disabled = any(item["api_key"] == selected_key and item["is_disabled"] for item in apikey_stats)
                if is_disabled:
                    if st.button("å•Ÿç”¨APIé‡‘é‘°"):
                        if toggle_apikey_status(selected_key, False):
                            st.success(f"å·²å•Ÿç”¨APIé‡‘é‘°: {selected_key}")
                            update_env_whitelist()
                            st.rerun()
                else:
                    if st.button("åœç”¨APIé‡‘é‘°"):
                        if toggle_apikey_status(selected_key, True):
                            st.success(f"å·²åœç”¨APIé‡‘é‘°: {selected_key}")
                            update_env_whitelist()
                            st.rerun()
            
            with col3:
                if st.button("åˆªé™¤APIé‡‘é‘°", type="primary", help="è­¦å‘Šï¼šæ­¤æ“ä½œä¸å¯é€†"):
                    if delete_apikey(selected_key):
                        st.success(f"å·²åˆªé™¤APIé‡‘é‘°: {selected_key}")
                        update_env_whitelist()
                        st.rerun()
            
            # æ›´æ–°æè¿°
            st.subheader("æ›´æ–°APIé‡‘é‘°æè¿°")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                selected_key_info = next((item for item in apikey_stats if item["api_key"] == selected_key), None)
                current_description = selected_key_info["description"] if selected_key_info else ""
                new_description = st.text_input("æè¿°", value=current_description)
            
            with col2:
                if st.button("æ›´æ–°æè¿°"):
                    if update_apikey_description(selected_key, new_description):
                        st.success(f"å·²æ›´æ–°APIé‡‘é‘°æè¿°")
                        st.rerun()
    
    # æ¨™ç±¤2ï¼šç”¢ç”Ÿæ–°APIé‡‘é‘°
    with tab2:
        st.header("ç”¢ç”Ÿæ–°APIé‡‘é‘°")
        
        with st.form("generate_apikey_form"):
            col1, col2 = st.columns([1, 3])
            
            with col1:
                prefix = st.text_input("åŠŸèƒ½ä»£ç¢¼ (2-8å€‹å­—æ¯æˆ–æ•¸å­—)", max_chars=8).upper()
            
            with col2:
                description = st.text_input("APIé‡‘é‘°æè¿° (ç”¨é€”ã€è² è²¬äººç­‰)")
            
            submit = st.form_submit_button("ç”¢ç”ŸAPIé‡‘é‘°")
            
            if submit:
                if not prefix:
                    st.error("è«‹è¼¸å…¥åŠŸèƒ½ä»£ç¢¼")
                elif not re.match(r"^[A-Z0-9]{2,8}$", prefix):
                    st.error("åŠŸèƒ½ä»£ç¢¼å¿…é ˆæ˜¯2-8å€‹å¤§å¯«å­—æ¯æˆ–æ•¸å­—")
                else:
                    new_apikey = generate_apikey(prefix)
                    
                    # æ·»åŠ åˆ°ç™½åå–®
                    add_to_whitelist(new_apikey, description)
                    
                    # æ›´æ–°.envæ–‡ä»¶
                    update_env_whitelist()
                    
                    st.success(f"å·²æˆåŠŸç”¢ç”Ÿæ–°APIé‡‘é‘°ï¼š{new_apikey}")
                    st.code(new_apikey)

if __name__ == "__main__":
    main() 